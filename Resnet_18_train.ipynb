{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170acf49",
   "metadata": {},
   "source": [
    "<h>William Kiger - Kristopher Gallagher<br>\n",
    "<h>DLH 598<br>\n",
    "<h>Build Pre-Trained Resnet-18 with Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945d3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec8df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Transformations \n",
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224), # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e522b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "{0: 'allergic_contact_dermatitis', 1: 'basal_cell_carcinoma', 2: 'folliculitis', 3: 'lichen_planus', 4: 'lupus_erythematosus', 5: 'neutrophilic_dermatoses', 6: 'photodermatoses', 7: 'psoriasis', 8: 'sarcoidosis', 9: 'squamous_cell_carcinoma'}\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "# Set train and valid directory paths\n",
    "\n",
    "root = 'data'\n",
    "\n",
    "train_directory = os.path.join(root, 'train')\n",
    "valid_directory = os.path.join(root, 'valid')\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(os.listdir(valid_directory))  \n",
    "print(num_classes)\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['valid'])\n",
    "}\n",
    "\n",
    "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "print(idx_to_class)\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data_loader = DataLoader(data['train'], batch_size=10, shuffle=True)\n",
    "valid_data_loader = DataLoader(data['valid'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9eb2b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e99a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data at hand: 3543\n",
      "Validation data at hand: 890\n"
     ]
    }
   ],
   "source": [
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "valid_data_size = len(data['valid'])\n",
    "\n",
    "print(\"Training data at hand: \" + str(train_data_size))\n",
    "print(\"Validation data at hand: \" + str(valid_data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bdba322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained is trained on ImageNet...just like our paper to replicate\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ffa9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf4275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_inputs = resnet18.fc.in_features\n",
    "\n",
    "resnet18.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, num_classes), #need to tune this for our number of classes.  10 in this case\n",
    "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")\n",
    "resnet18 = resnet18.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1f9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(resnet18.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf18c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Model Being Saved...\n",
      "Epoch : 000, Training: Loss - 2.1262, Accuracy - 23.5394%, \n",
      "\t\tValidation : Loss - 2.0190, Accuracy - 26.1798%, Time: 46.3860s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 001, Training: Loss - 1.9576, Accuracy - 30.4826%, \n",
      "\t\tValidation : Loss - 1.9505, Accuracy - 29.3258%, Time: 42.6097s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 002, Training: Loss - 1.8942, Accuracy - 33.3898%, \n",
      "\t\tValidation : Loss - 1.9312, Accuracy - 32.3596%, Time: 44.6234s\n",
      "Epoch : 003, Training: Loss - 1.8661, Accuracy - 34.9421%, \n",
      "\t\tValidation : Loss - 1.9606, Accuracy - 29.6629%, Time: 44.9010s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 004, Training: Loss - 1.8355, Accuracy - 35.9300%, \n",
      "\t\tValidation : Loss - 1.8926, Accuracy - 33.2584%, Time: 47.8811s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 005, Training: Loss - 1.7752, Accuracy - 38.0186%, \n",
      "\t\tValidation : Loss - 1.8626, Accuracy - 35.5056%, Time: 48.7720s\n",
      "Epoch : 006, Training: Loss - 1.8004, Accuracy - 37.2848%, \n",
      "\t\tValidation : Loss - 1.8873, Accuracy - 32.9213%, Time: 46.7976s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 007, Training: Loss - 1.7252, Accuracy - 40.0226%, \n",
      "\t\tValidation : Loss - 1.8233, Accuracy - 35.0562%, Time: 41.7642s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 008, Training: Loss - 1.7062, Accuracy - 40.6435%, \n",
      "\t\tValidation : Loss - 1.8164, Accuracy - 36.5169%, Time: 42.1153s\n",
      "Epoch : 009, Training: Loss - 1.7248, Accuracy - 39.8532%, \n",
      "\t\tValidation : Loss - 1.8204, Accuracy - 36.7416%, Time: 42.4949s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 010, Training: Loss - 1.6954, Accuracy - 39.9379%, \n",
      "\t\tValidation : Loss - 1.8014, Accuracy - 36.5169%, Time: 43.7207s\n",
      "Epoch : 011, Training: Loss - 1.6791, Accuracy - 40.6153%, \n",
      "\t\tValidation : Loss - 1.8116, Accuracy - 36.1798%, Time: 43.4313s\n",
      "Epoch : 012, Training: Loss - 1.6627, Accuracy - 42.2523%, \n",
      "\t\tValidation : Loss - 1.8089, Accuracy - 37.3034%, Time: 43.9680s\n",
      "Epoch : 013, Training: Loss - 1.6458, Accuracy - 42.1394%, \n",
      "\t\tValidation : Loss - 1.8258, Accuracy - 38.0899%, Time: 44.9716s\n",
      "Epoch : 014, Training: Loss - 1.6497, Accuracy - 42.5628%, \n",
      "\t\tValidation : Loss - 1.8061, Accuracy - 37.6404%, Time: 40.4870s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 015, Training: Loss - 1.6329, Accuracy - 43.6071%, \n",
      "\t\tValidation : Loss - 1.7635, Accuracy - 37.5281%, Time: 42.4802s\n",
      "Epoch : 016, Training: Loss - 1.6375, Accuracy - 42.6192%, \n",
      "\t\tValidation : Loss - 1.7810, Accuracy - 38.8764%, Time: 46.7060s\n",
      "Epoch : 017, Training: Loss - 1.6215, Accuracy - 43.6071%, \n",
      "\t\tValidation : Loss - 1.7894, Accuracy - 37.7528%, Time: 44.3660s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 018, Training: Loss - 1.6305, Accuracy - 43.2684%, \n",
      "\t\tValidation : Loss - 1.7594, Accuracy - 39.6629%, Time: 43.7570s\n",
      "Epoch : 019, Training: Loss - 1.6007, Accuracy - 44.1998%, \n",
      "\t\tValidation : Loss - 1.7635, Accuracy - 39.6629%, Time: 47.2540s\n",
      "Epoch : 020, Training: Loss - 1.5743, Accuracy - 44.7925%, \n",
      "\t\tValidation : Loss - 1.8244, Accuracy - 38.7640%, Time: 47.6930s\n",
      "Epoch : 021, Training: Loss - 1.5827, Accuracy - 45.4982%, \n",
      "\t\tValidation : Loss - 1.8348, Accuracy - 38.6517%, Time: 48.6550s\n",
      "Epoch : 022, Training: Loss - 1.6018, Accuracy - 44.0869%, \n",
      "\t\tValidation : Loss - 1.8005, Accuracy - 36.9663%, Time: 46.3480s\n",
      "Epoch : 023, Training: Loss - 1.5578, Accuracy - 45.8369%, \n",
      "\t\tValidation : Loss - 1.7745, Accuracy - 38.9888%, Time: 44.4400s\n",
      "Epoch : 024, Training: Loss - 1.5808, Accuracy - 44.4539%, \n",
      "\t\tValidation : Loss - 1.7823, Accuracy - 39.4382%, Time: 45.2300s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 025, Training: Loss - 1.5772, Accuracy - 44.4539%, \n",
      "\t\tValidation : Loss - 1.7518, Accuracy - 39.2135%, Time: 44.2120s\n",
      "Epoch : 026, Training: Loss - 1.5527, Accuracy - 45.7240%, \n",
      "\t\tValidation : Loss - 1.8638, Accuracy - 36.7416%, Time: 44.6950s\n",
      "Epoch : 027, Training: Loss - 1.5702, Accuracy - 45.4135%, \n",
      "\t\tValidation : Loss - 1.7670, Accuracy - 40.6742%, Time: 44.4670s\n",
      "Epoch : 028, Training: Loss - 1.5511, Accuracy - 46.2602%, \n",
      "\t\tValidation : Loss - 1.7525, Accuracy - 39.4382%, Time: 44.9020s\n",
      "Epoch : 029, Training: Loss - 1.5444, Accuracy - 45.3853%, \n",
      "\t\tValidation : Loss - 1.8039, Accuracy - 39.8876%, Time: 44.4050s\n",
      "Epoch : 030, Training: Loss - 1.5550, Accuracy - 46.6836%, \n",
      "\t\tValidation : Loss - 1.7783, Accuracy - 39.4382%, Time: 44.1110s\n",
      "Epoch : 031, Training: Loss - 1.5327, Accuracy - 45.7804%, \n",
      "\t\tValidation : Loss - 1.8364, Accuracy - 38.5393%, Time: 44.7170s\n",
      "Epoch : 032, Training: Loss - 1.5321, Accuracy - 45.5828%, \n",
      "\t\tValidation : Loss - 1.7981, Accuracy - 38.4270%, Time: 44.2620s\n",
      "Epoch : 033, Training: Loss - 1.5363, Accuracy - 45.6957%, \n",
      "\t\tValidation : Loss - 1.8245, Accuracy - 39.4382%, Time: 43.1100s\n",
      "Epoch : 034, Training: Loss - 1.5207, Accuracy - 46.7965%, \n",
      "\t\tValidation : Loss - 1.7773, Accuracy - 40.4494%, Time: 44.4730s\n",
      "Epoch : 035, Training: Loss - 1.5271, Accuracy - 47.4174%, \n",
      "\t\tValidation : Loss - 1.7995, Accuracy - 39.8876%, Time: 44.5190s\n",
      "Epoch : 036, Training: Loss - 1.5126, Accuracy - 46.4014%, \n",
      "\t\tValidation : Loss - 1.7716, Accuracy - 40.5618%, Time: 44.4770s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 037, Training: Loss - 1.5230, Accuracy - 46.5143%, \n",
      "\t\tValidation : Loss - 1.7517, Accuracy - 40.0000%, Time: 44.9630s\n",
      "Epoch : 038, Training: Loss - 1.5063, Accuracy - 47.2481%, \n",
      "\t\tValidation : Loss - 1.7811, Accuracy - 39.8876%, Time: 44.4350s\n",
      "Epoch : 039, Training: Loss - 1.4956, Accuracy - 46.7965%, \n",
      "\t\tValidation : Loss - 1.7572, Accuracy - 40.0000%, Time: 44.3050s\n",
      "Epoch : 040, Training: Loss - 1.5000, Accuracy - 47.8408%, \n",
      "\t\tValidation : Loss - 1.7923, Accuracy - 39.5506%, Time: 43.6576s\n",
      "Epoch : 041, Training: Loss - 1.4892, Accuracy - 47.3610%, \n",
      "\t\tValidation : Loss - 1.8362, Accuracy - 38.0899%, Time: 42.8490s\n",
      "New Best Model Being Saved...\n",
      "Epoch : 042, Training: Loss - 1.4998, Accuracy - 47.0787%, \n",
      "\t\tValidation : Loss - 1.7332, Accuracy - 39.3258%, Time: 45.7097s\n",
      "Epoch : 043, Training: Loss - 1.4966, Accuracy - 47.3328%, \n",
      "\t\tValidation : Loss - 1.8005, Accuracy - 38.4270%, Time: 43.0480s\n",
      "Epoch : 044, Training: Loss - 1.4809, Accuracy - 48.1513%, \n",
      "\t\tValidation : Loss - 1.7845, Accuracy - 38.9888%, Time: 43.1610s\n",
      "Epoch : 045, Training: Loss - 1.4803, Accuracy - 48.6593%, \n",
      "\t\tValidation : Loss - 1.7615, Accuracy - 40.8989%, Time: 46.0310s\n",
      "Epoch : 046, Training: Loss - 1.4747, Accuracy - 47.0223%, \n",
      "\t\tValidation : Loss - 1.7491, Accuracy - 40.6742%, Time: 43.6530s\n",
      "Epoch : 047, Training: Loss - 1.4854, Accuracy - 47.8126%, \n",
      "\t\tValidation : Loss - 1.7650, Accuracy - 40.3371%, Time: 43.8100s\n",
      "Epoch : 048, Training: Loss - 1.4864, Accuracy - 47.5021%, \n",
      "\t\tValidation : Loss - 1.8024, Accuracy - 38.5393%, Time: 44.5700s\n"
     ]
    }
   ],
   "source": [
    "#get training...\n",
    "train_start_time = time.time() \n",
    "\n",
    "#we are saving the model at the best validation loss, so run a lot of epochs...\n",
    "epochs = 50\n",
    "\n",
    "#for training metrics downstream\n",
    "best_loss = 999999.0 #high so saves at base case\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Loss and Accuracy within the epoch\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0    \n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    \n",
    "    #put model in training mode \n",
    "    resnet18.train()\n",
    "    \n",
    "    # training batches\n",
    "    for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "#         i+=1\n",
    "        \n",
    "        inputs = inputs.to(device) #gpu...we hope...\n",
    "        labels = labels.to(device) \n",
    "        \n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "        outputs = resnet18(inputs) #forward pass\n",
    "        loss = loss_func(outputs, labels) #compute loss\n",
    "        loss.backward() #backpropagate gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute the total loss for the batch and add it to train_loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(outputs.data, 1)[1]\n",
    "        correct_counts = predicted.eq(labels.data.view_as(predicted))\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "        train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "#         print(\"here\")\n",
    "        resnet18.eval() #eval mode\n",
    "        \n",
    "#         for b, (inputs, labels) in tqdm(enumerate(valid_data_loader)):\n",
    "        for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "#             j+=1\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "            \n",
    "            # Apply the model\n",
    "            y_val = resnet18(inputs)\n",
    "            v_loss = loss_func(y_val, labels) #compute loss\n",
    "            valid_loss += v_loss.item() * inputs.size(0) #total loss for the batch and add it to valid_loss\n",
    "        \n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "#             tst_corr += (predicted == labels).sum()\n",
    "            \n",
    "            #valid accuracy\n",
    "            correct_counts = predicted.eq(labels.data.view_as(predicted))\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            valid_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "    #store model if validation loss is less than best historical loss        \n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        print(\"New Best Model Being Saved...\")\n",
    "        torch.save(resnet18, 'resnet_18_derm_model_test.pt')\n",
    "            \n",
    "    #store train metrics        \n",
    "    avg_train_loss = train_loss/train_data_size\n",
    "    train_losses.append(avg_train_loss)\n",
    "    avg_train_acc = train_acc/train_data_size\n",
    "    train_acc_list.append(avg_train_acc)\n",
    "    \n",
    "    #store validation metrics \n",
    "    avg_valid_loss = valid_loss/valid_data_size \n",
    "    test_losses.append(avg_valid_loss)\n",
    "    avg_valid_acc = valid_acc/valid_data_size\n",
    "    test_acc_list.append(avg_valid_acc)\n",
    "        \n",
    "    epoch_end = time.time()\n",
    "    epoch_time = epoch_end-epoch_start\n",
    "    print(\"Epoch : {:03d}, Training: Loss - {:.4f}, Accuracy - {:.4f}%, \\n\\t\\tValidation : Loss - {:.4f}, Accuracy - {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_time))\n",
    "           \n",
    "train_end_time = time.time() \n",
    "total_train_time = train_end_time - train_start_time\n",
    "print(\"Total Training Time Was: \" + str(total_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b921e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot([t/100 for t in train_acc_list], label='training accuracy')\n",
    "# plt.plot([t/100 for t in test_acc_list], label='validation accuracy')\n",
    "plt.plot(train_acc_list, label='training loss')\n",
    "plt.plot(test_acc_list, label='validation loss')\n",
    "plt.title('Accuracy at the end of each epoch')\n",
    "plt.legend();\n",
    "\n",
    "print(train_acc_list)\n",
    "print(test_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d60543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loader for the entire the test set\n",
    "test_load_all = DataLoader(data['valid'], batch_size=10000, shuffle=False)\n",
    "class_names = list(idx_to_class.values()) #classes are stored in a dictionary\n",
    "# print(class_names)\n",
    "\n",
    "resnet18.eval() #eval mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for X_test, y_test in test_load_all:\n",
    "        \n",
    "        X_test = X_test.to(device)\n",
    "        y_test = y_test.to(device) \n",
    "        \n",
    "        y_val = resnet18(X_test)\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "\n",
    "# arr = confusion_matrix(y_test.view(-1), predicted.view(-1))\n",
    "y_test = y_test.cpu().numpy()\n",
    "predicted = predicted.cpu().numpy()\n",
    "# print(y_test)\n",
    "# print(predicted)\n",
    "arr = confusion_matrix(y_test.reshape(-1), predicted.reshape(-1))\n",
    "df_cm = pd.DataFrame(arr, class_names, class_names)\n",
    "plt.figure(figsize = (9,6))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"label (ground truth)\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aaa08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure model is in eval mode \n",
    "resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b96824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for inference...\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"2731.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ac8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = transform(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_image_name):\n",
    "\n",
    "    transform = image_transforms['valid']\n",
    "\n",
    "    test_image = Image.open(test_image_name)\n",
    "    plt.imshow(test_image)\n",
    "    \n",
    "    test_image_tensor = transform(test_image)\n",
    "    if torch.cuda.is_available():\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(test_image_tensor)\n",
    "        ps = torch.exp(out)\n",
    "\n",
    "        topk, topclass = ps.topk(10, dim=1)\n",
    "        cls = idx_to_class[topclass.cpu().numpy()[0][0]]\n",
    "        score = topk.cpu().numpy()[0][0]\n",
    "\n",
    "        for i in range(10):\n",
    "            print(\"Prediction\", i+1, \":\", idx_to_class[topclass.cpu().numpy()[0][i]], \", Score: \", topk.cpu().numpy()[0][i]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference test\n",
    "model = torch.load(\"data_model.pt\")\n",
    "inference(model, \"2731.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ffd09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
