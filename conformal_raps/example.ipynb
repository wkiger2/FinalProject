{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aangelopoulos/conformal_classification/blob/master/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29GmWHMgSe-c"
   },
   "source": [
    "# Exploring `RAPS`\n",
    "This is a colab that shows you how to generate predictive sets guaranteed to contain the true class label with a probability you specify. \n",
    "\n",
    "This technique was proposed in our work [Uncertainty Sets for Image Classifiers using Conformal Prediction](https://arxiv.org/abs/).\n",
    "\n",
    "## Setting up the experiments\n",
    "\n",
    "**Make sure you're using a GPU** by setting \"Runtime/Change runtime type/Hardware accelerator/\" to \"GPU\" in the colab menu above.  \n",
    "\n",
    "First, let's deal with imports, loading the pretrained model, and other boilerplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIiBD-pFVdkD",
    "outputId": "2c29d397-aadd-4860-b33e-acfc13a4c389"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WilliamKiger\\Anaconda3\\envs\\conformal\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\WilliamKiger\\Anaconda3\\envs\\conformal\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# !rm -r conformal_classification\n",
    "# !git clone https://github.com/aangelopoulos/conformal_classification.git\n",
    "import os, sys, inspect\n",
    "sys.path.insert(1, os.path.join(sys.path[0], './conformal_classification/'))\n",
    "\n",
    "from conformal import *\n",
    "from utils import *\n",
    "\n",
    "# Import other standard packages\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "\n",
    "# Fix the random seed for reproducibility (you can change this, of course) \n",
    "seed=0\n",
    "np.random.seed(seed=seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Normalization from torchvision repo\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std= [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "cudnn.benchmark = True\n",
    "batch_size = 128\n",
    "\n",
    "# Get your model\n",
    "model = torchvision.models.resnet152(pretrained=True,progress=True).cuda()\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLpbIPuQE2_Y"
   },
   "source": [
    "Now download and extract ImageNet-Val. You only need to execute this cell once and it takes less than 5 minutes to run on my system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXIhg9BDfwNX",
    "outputId": "7f5791ac-2cc7-4bea-b684-60b51e4fcedb"
   },
   "outputs": [],
   "source": [
    "# !wget -nv -O imagenet_val.tar.gz -L https://berkeley.box.com/shared/static/pouthcomrvxw9hj64oxhacjvqdw3ihlp.gz\n",
    "# !mkdir imagenet_val\n",
    "# !tar -xf imagenet_val.tar.gz -C ./imagenet_val/ \n",
    "# !mv imagenet_val/scratch/group/ilsvrc/val/* imagenet_val/\n",
    "# !rm -r imagenet_val/scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc3YXNnEHTr_"
   },
   "source": [
    "Now get the conformal calibration set and the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qGk9JD41oz74"
   },
   "outputs": [],
   "source": [
    "num_calib = 5000\n",
    "\n",
    "# Get the conformal calibcration dataset\n",
    "imagenet_calib_data, imagenet_val_data = torch.utils.data.random_split(torchvision.datasets.ImageFolder('./imagenet_val/', transform), [num_calib,50000-num_calib])\n",
    "\n",
    "# Initialize loaders \n",
    "calib_loader = torch.utils.data.DataLoader(imagenet_calib_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(imagenet_val_data, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x261109a54e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calib_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x261109ca020>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWj_0QpVJRHl"
   },
   "source": [
    "\n",
    "\n",
    "## Conformalizing the model\n",
    "\n",
    "This this the key step, where you perform Platt scaling and then wrap the model with `RAPS`.\n",
    "\n",
    " *(Did you catch the joke?)*\n",
    "\n",
    "You should experiment with different values of `alpha` and `lamda_criterion`=`'size'` or `'adaptiveness'` to see how the sets change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luI64fsJJPKn",
    "outputId": "757d3157-db23-47fa-c98a-9b3611f97372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Platt scaling.\n",
      "Computing logits for model (only happens once).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:47<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal T=4.433741569519043\n"
     ]
    }
   ],
   "source": [
    "# Conformalize model\n",
    "cmodel = ConformalModel(model, calib_loader, alpha=0.1, lamda_criterion='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnSfcH2qJhzv"
   },
   "source": [
    "**Congratulations!** You can now output `1-alpha` predictive sets.\n",
    "\n",
    "\n",
    "Now you can validate the coverage of your conformal model on the validation set with this utility function.\n",
    "\n",
    "Running averages of coverage and size are in parentheses.\n",
    "\n",
    "**Feel free to stop execution of this cell at any time**; otherwise it will run until `N=50,000-num_calib`, since that's the size of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jG5vn3NJf4f",
    "outputId": "534930fa-0b50-4a0f-a1ea-d5033f701da6"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 976 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m top1, top5, coverage, size \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_bool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\TEST\\conformal_classification\\conformal_classification-master\\utils.py:58\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(val_loader, model, print_bool)\u001b[0m\n\u001b[0;32m     56\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m output, S \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# measure accuracy and record loss\u001b[39;00m\n\u001b[0;32m     60\u001b[0m prec1, prec5 \u001b[38;5;241m=\u001b[39m accuracy(output, target, topk\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\conformal\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\TEST\\conformal_classification\\conformal_classification-master\\conformal.py:50\u001b[0m, in \u001b[0;36mConformalModel.forward\u001b[1;34m(self, randomized, allow_zero_sets, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     scores \u001b[38;5;241m=\u001b[39m softmax(logits_numpy\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mitem(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     48\u001b[0m     I, ordered, cumsum \u001b[38;5;241m=\u001b[39m sort_sum(scores)\n\u001b[1;32m---> 50\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[43mgcq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcumsum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandomized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_zero_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_zero_sets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, S\n",
      "File \u001b[1;32m~\\Desktop\\TEST\\conformal_classification\\conformal_classification-master\\conformal.py:185\u001b[0m, in \u001b[0;36mgcq\u001b[1;34m(scores, tau, I, ordered, cumsum, penalties, randomized, allow_zero_sets)\u001b[0m\n\u001b[0;32m    182\u001b[0m     V \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(sizes_base\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sizes_base\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    184\u001b[0m         V[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mordered[i,sizes_base[i]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m--> 185\u001b[0m                 (tau\u001b[38;5;241m-\u001b[39m(cumsum[i,sizes_base[i]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mordered[i,sizes_base[i]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[43mpenalties_cumsum\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msizes_base\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# -1 since sizes_base \\in {1,...,1000}.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m sizes_base \u001b[38;5;241m-\u001b[39m (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom(V\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m V)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 976 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "top1, top5, coverage, size = validate(val_loader, cmodel, print_bool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_rGtCijW8aA"
   },
   "source": [
    "That's it! You're ready to use RAPS.\n",
    "\n",
    "As a final visualization, running the next cell will just sample random 5 images and show their RAPS sets. Note that you can avoid sets of size zero by setting `randomized=False`.\n",
    "\n",
    "It's interesting to see which images the model thinks are more difficult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "9z6WnKryYYNJ",
    "outputId": "eca2170d-824d-4e6b-93d1-dae6dbc156f6"
   },
   "outputs": [],
   "source": [
    "num_images = 8\n",
    "explore_data, _ = torch.utils.data.random_split(imagenet_val_data, [num_images, 50000-num_calib-num_images])\n",
    "\n",
    "import pdb\n",
    "import json\n",
    "\n",
    "!wget -nv -O human_readable_labels.json -L https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\n",
    "\n",
    "with open('human_readable_labels.json') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "labeldict = {}\n",
    "for i in range(len(labels)):\n",
    "  labeldict[i] = labels[i]\n",
    "  \n",
    "mosaiclist = []\n",
    "sets = []\n",
    "labels = []\n",
    "\n",
    "for data in explore_data:\n",
    "  img, label = data\n",
    "  scores, set = cmodel(img.view(1,3,224,224).cuda())\n",
    "  unnormalized_img = (img * torch.Tensor([0.229, 0.224, 0.225]).view(-1,1,1))+torch.Tensor([0.485, 0.456, 0.406]).view(-1,1,1)\n",
    "  \n",
    "  set = [labeldict[s] for s in set[0]]\n",
    "  sets = sets + [set]\n",
    "  labels = labels + [labeldict[label]]\n",
    "  mosaiclist = mosaiclist + [unnormalized_img]\n",
    "\n",
    "grid = torchvision.utils.make_grid(mosaiclist)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(min(num_images,9)*5, np.floor(num_images/9+1)*5))\n",
    "ax.imshow(grid.permute(1,2,0), interpolation='nearest')\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(len(mosaiclist)):\n",
    "  print(f\"Image {i} has label \\'{labels[i]}\\', and the predictive set is {sets[i]}.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
